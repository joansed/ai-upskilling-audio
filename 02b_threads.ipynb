{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adeaa261",
   "metadata": {},
   "source": [
    "# Fast Data Pipeline with Threading\n",
    "\n",
    "The GIL means that threads are not always helpful in Python, but there are two special cases where Python threading can be helpful:\n",
    "* I/O operations can occur without blocking the GIL, and\n",
    "* Calls to C++/Rust libraries (eg, many librosa operations) release the GIL while doing the heavy lifting.\n",
    "\n",
    "In both of these cases, we can improve execution speed by parallelizing effectively. \n",
    "\n",
    "This is particularly important for *data pipelines*. When training a model, we typically need to feed it subsets of our (gigantic, too big to fit in memory) dataset. Without threading, we need to load the next batch of data, wait for the model to evaluate and update, then load the next batch of data, and so on. This means that our fancy GPU is going to waste time while we load the data!\n",
    "\n",
    "Instead, we can load data *while* the model is running, and (hopefully) have the next batch of data ready and waiting. This greatly improves throughput. At the same time, we can make the data loader multi-threaded, to load data from more files in parallel (ie, faster).\n",
    "\n",
    "Let's start with a very simple example of how to use a `ThreadPoolExecutor`.\n",
    "\n",
    "To use the executor:\n",
    "1) Set it up, with some number of `max_workers`.\n",
    "2) Use `executor.submit(fn, arg1, arg2, ...)` to give the workers some work. The worker will run the submitted function, and evaluate it with the provided arguments - `fn(arg1, arg2, ...)`. This submit call returns a *future* object, which you should store for later to get the results.\n",
    "3) Get results from the future objects.\n",
    "\n",
    "Here's some example code to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256a8b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# The function we want the workers to evaluate.\n",
    "fun = lambda a: a**2\n",
    "\n",
    "# Create an `executor` that we can pass work to.\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "  results = []\n",
    "  for i in range(10):\n",
    "    # Each result is a `future` object, which can tell us whether\n",
    "    # it is still running, and eventually provide a result.\n",
    "    results.append(executor.submit(fun, i))\n",
    "  results = [r.result() for r in results]\n",
    "  print(results)\n",
    "\n",
    "# We can also use a `map` approach more concisely.\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "  # map_results is a generator, yielding results as they are ready.\n",
    "  map_results = executor.map(fun, range(10))\n",
    "  print(list(map_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from typing import Generator\n",
    "from etils import epath\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tqdm\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AudioExample:\n",
    "  audio: np.ndarray\n",
    "  file_id: str\n",
    "  offset: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec0aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# ðŸ“ Exercise 0 â€“ Plain Old Data Loader\n",
    "# ------------------------------------------------------------\n",
    "# First, write a data loader which loads audio data from a\n",
    "# directory. The data loader should yield `AudioExample` objects\n",
    "# with the following fields:\n",
    "# - `audio`: the audio data as a numpy array\n",
    "# - `file_id`: the file name of the audio file\n",
    "# - `offset`: the offset in seconds of the audio file\n",
    "# The data loader should load all audio files in the directory\n",
    "# and yield them one by one. The audio files are in WAV format.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def data_loader(\n",
    "    base_path: str,\n",
    "    file_glob: str, \n",
    "    window_size_s: float,\n",
    "    sample_rate: int) -> Generator[AudioExample, None, None]:\n",
    "  \"\"\"Loads audio files from a directory and yields AudioExample objects.\"\"\"\n",
    "  raise NotImplementedError(\n",
    "      'Implement the data_loader function to load audio files from a directory.'\n",
    "  )\n",
    "\n",
    "for x in tqdm.tqdm(data_loader(\n",
    "    '/mnt/class_data/anuraset', \n",
    "    'raw_data/INCT17/*.wav', \n",
    "    5.0, 32000)):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b047b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# ðŸ“ Exercise 1 â€“ Threaded Old Data Loader\n",
    "# ------------------------------------------------------------\n",
    "# Next, write a threaded version of the data loader.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def threaded_data_loader(\n",
    "    base_path: str,\n",
    "    file_glob: str, \n",
    "    window_size_s: float,\n",
    "    sample_rate: int,\n",
    "    max_workers: int = 2) -> Generator[AudioExample, None, None]:\n",
    "  \"\"\"Loads audio files from a directory and yields AudioExample objects.\"\"\"\n",
    "  raise NotImplementedError(\n",
    "      'Implement the threaded_data_loader function to load audio files from a directory.'\n",
    "  )\n",
    "\n",
    "for x in tqdm.tqdm(threaded_data_loader(\n",
    "    '/mnt/class_data/anuraset', \n",
    "    'raw_data/INCT17/*.wav', \n",
    "    5.0, 32000, max_workers=2)):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63f411",
   "metadata": {},
   "source": [
    "**Extra challenge:**\n",
    "Our current data iterator is pretty good, but has a subtle failure mode: If we process the data slower than the iterator loads the data, we can wind up with an ever-growing backlog of loaded data, until we run out of memory. Refactor the data loader so that it only preloads a fixed number of examples at a time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
